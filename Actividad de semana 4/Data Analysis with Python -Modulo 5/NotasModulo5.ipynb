{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**MODULO 5 - Model Evaluation and Refinement**\n",
        "\n",
        "**Curso:** Ciencia y analitica de Datos  \n",
        "**Matricula:** A01793718  \n",
        "**Nombre:** Cristian Reynaldo Miranda Jimenez  \n",
        "\n"
      ],
      "metadata": {
        "id": "qweaq4G4pv26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Evaluation**\n",
        "\n",
        "In-sample evaluation tells us how well our model fits the data already given to train it.\n",
        "    \n",
        "It does not give us an estimate of how well the trained model can predict new data.\n",
        "    \n",
        "The solution is to split our data up, use the In-sample data or training data to train the model.  \n",
        "  \n",
        "The rest of the data called test data is used as out-of-sample data.\n",
        "\n",
        "  \n",
        "#### **Errors**\n",
        "Generalization error is a measure of how well our data does at predicting previously unseen data.  \n",
        "  \n",
        "The error we obtain using our testing data is an approximation of this error.\n",
        "\n",
        "\n",
        "#### **Cross Validation**\n",
        "- Most common out-of-sample evaluation metrics\n",
        "- More efective use of data "
      ],
      "metadata": {
        "id": "5xxUPpKLulZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict"
      ],
      "metadata": {
        "id": "bTKZbzGHpzI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training / test data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=0)\n",
        "\n",
        "\n",
        "# Cross validation\n",
        "scores = cross_val_score(model, x_Data, y_data, cv=3)\n",
        "np.mean(scores) # average result\n",
        "\n",
        "# Predicted cross val\n",
        "yhat = cross_val_predict(model, x_Data, y_data, cv=3)"
      ],
      "metadata": {
        "id": "W511QIrovVLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overfitting, Underfitting and Model Selection**\n",
        "\n",
        "This is called under-fitting, where the model is too simple to fit the data.\n",
        "\n",
        "This is called over-fitting, where the model is too flexible and fits the noise rather than the function."
      ],
      "metadata": {
        "id": "TmdttbSD30ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rsqu_test = []\n",
        "order = [1,2,3,4]\n",
        "\n",
        "for n in order:\n",
        "  pr = PolynomialFeatures(degree=n)\n",
        "  x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
        "  x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
        "\n",
        "  lr.fit(x_train_pr, y_train)\n",
        "\n",
        "  Rsqu_test.append(lr.score(x_test_pr,y_test))"
      ],
      "metadata": {
        "id": "_6zykmhb3G59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ridge Regression**\n",
        "\n",
        "Ridge regression prevents over-fitting.\n",
        "  \n",
        "Ridge regression controls the magnitude of these polynomial coefficients by introducing the parameter alpha.\n",
        "  \n",
        "Alpha is a parameter we select before fitting or training the model.\n",
        "\n",
        "In order to select alpha we use cross-validation."
      ],
      "metadata": {
        "id": "-cHAULHf73Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "RideModel = Ridge(alpha=0.1)\n",
        "RideModel.fit(X,y)\n",
        "\n",
        "yhat = RideModel.predict(X)\n"
      ],
      "metadata": {
        "id": "Kn2-jabq3G9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grid Search**\n",
        "\n",
        "Grid search allows us to scan through multiple free parameters with few lines of code.\n",
        "\n",
        "Parameters like the alpha term discussed in the previous video are not part of the fitting or training process. These values are called hyperparameters.\n",
        "\n",
        "Grid search takes the model or objects you would like to train and different values of the hyperparameters.\n",
        "It then calculates the mean square error or R squared for various hyperparameter values, allowing you to choose the best values."
      ],
      "metadata": {
        "id": "Ijd7DS61gDmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'alpha':[1,10,100,1000],\n",
        "              'normalize': [True, False]\n",
        "              }\n",
        "\n",
        "RR = Ridge()\n",
        "\n",
        "Grid1 = GridSearchCV(RR, parameters, cv = 4)\n",
        "\n",
        "Grid1.fit(x_data, y_data)\n",
        "\n",
        "Grid1.best_estimator_\n",
        "\n",
        "scores = Grid1.cv_results_\n",
        "scores['mean_test_score']\n"
      ],
      "metadata": {
        "id": "c3GTL8dPg-OH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}